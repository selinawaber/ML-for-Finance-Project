{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62ebba-1157-4110-9127-962de2bc9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d1473-886a-4f4f-8ca1-0edab48cd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_crossvalidation(func, X_test, y_test):\n",
    "  \n",
    "  std_best_score = func.cv_results_[\"std_test_score\"][func.best_index_]\n",
    "  print(f\"Best parameters: {func.best_params_}\")\n",
    "  print(f\"Mean CV score: {func.best_score_:}\")\n",
    "  print(f\"Standard deviation of CV score: {std_best_score:}\")\n",
    "  print(\"Test Score:\".format(func.score(X_test, y_test)))\n",
    "\n",
    "def report(y_true, y_pred):\n",
    "    \n",
    "  class_report = metrics.classification_report(y_true, y_pred)\n",
    "  print(class_report)\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred, normalize = \"all\")\n",
    "  conf_matrix = pd.DataFrame(conf_matrix, [\"Class 0\", \"Class 1\", \" Class 2\", \"Class 3\", \" Class 4\"],  [\"Class 0\", \"Class 1\", \" Class 2\", \"Class 3\", \" Class 4\"])\n",
    "  sns.heatmap(conf_matrix, annot = True).set(xlabel = \"Assigned Class\", ylabel = \"True Class\", title = \"Confusion Matrix\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348af014-4659-45cb-883e-59515fba19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddefad1-a25e-4883-a048-b2768939fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"GroupProjectDataSet.csv\", sep=',')\n",
    "print('Shape of data frame:', df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf479e-d223-4a7c-9cf5-13e5045d79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values for variables where appropriate\n",
    "\n",
    "df[\"PoolQC\"] = df[\"PoolQC\"].fillna(value = \"None\")\n",
    "df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(value = \"None\")\n",
    "df[\"Alley\"] = df[\"Alley\"].fillna(value = \"None\")\n",
    "df[\"Fence\"] = df[\"Fence\"].fillna(value = \"None\")\n",
    "df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(value = \"None\")\n",
    "df[\"GarageCond\"] = df[\"GarageCond\"].fillna(value = \"None\")\n",
    "df[\"GarageType\"] = df[\"GarageType\"].fillna(value = \"None\")\n",
    "df[\"GarageFinish\"] = df[\"GarageFinish\"].fillna(value = \"None\")\n",
    "df[\"GarageQual\"] = df[\"GarageQual\"].fillna(value = \"None\")\n",
    "df[\"BsmtFinType2\"] = df[\"BsmtFinType2\"].fillna(value = \"None\")\n",
    "df[\"BsmtExposure\"] = df[\"BsmtExposure\"].fillna(value = \"None\")\n",
    "df[\"BsmtQual\"] = df[\"BsmtQual\"].fillna(value = \"None\")\n",
    "df[\"BsmtCond\"] = df[\"BsmtCond\"].fillna(value = \"None\")\n",
    "df[\"BsmtFinType1\"] = df[\"BsmtFinType1\"].fillna(value = \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7530208-bfb4-4f79-a091-4b5158d4be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe42acf-162a-472e-af01-6cb02ada6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values for the variables\n",
    "\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([missing, percent], axis=1, keys=['Nr. of missing values', 'Share'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b8231-83a3-4c9d-b520-512ad970fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Dealing with Categorical Features (Encoding Categorical Variables) / Splitting Into X and y\n",
    "\n",
    "# Numerical variables that should be handled as categorical variables\n",
    "df = df.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"}})\n",
    "df = df.replace({\"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4267ae-768b-48ef-83af-23c7f15909ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign response to y\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Factorize categorical values, assign output to X\n",
    "# create (multiple) dummy variables for a categorical variable\n",
    "# panda way\n",
    "X = pd.get_dummies(df.iloc[:, :-1])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b460c5d-bdb6-468f-bbd8-df4ac3638629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ab hier Ã¼bernehmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cf913-258b-4b8e-949a-da15b7564c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Selection##\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Plotting Heatmap\n",
    "plt.figure(figsize = (10,6))\n",
    "sns.heatmap(corr, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25523e-b8f5-4a88-bd30-0a3a46d06731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Sort the correlations with respect to 'Class'\n",
    "corr_with_class = corr_matrix['Class'].sort_values(ascending=False)\n",
    "\n",
    "# Print the correlations\n",
    "print(corr_with_class)\n",
    "\n",
    "# Select the top 10 features with the highest correlation\n",
    "top_features = corr_with_class.nlargest(10).index\n",
    "\n",
    "# Print the top features\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd00e3-e821-43ef-aa47-6209434e0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VIF## \n",
    "\n",
    "# load the data and select features\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea',\n",
    "        'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "\n",
    "# add a constant to X for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "\n",
    "# print the VIF table\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438be289-a089-4315-b962-edf185e165e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######KNN#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69344e0-30f1-4b2b-9e44-6489a8b68507",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Partitioning of the Data Set Into Train and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c300d91-7288-4f62-800c-c9ce43c63b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN-Model##\n",
    "train_df = pd.DataFrame(data=X_train, columns=X.columns)\n",
    "train_df['Class'] = y_train\n",
    "\n",
    "test_df = pd.DataFrame(data=X_test, columns=X.columns)\n",
    "test_df['Class'] = y_test\n",
    "\n",
    "X_train = train_df[['Class', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "y_train = train_df['Class']\n",
    "\n",
    "# Initialize the KNN classifier with k=20\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# Fit the KNN model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained KNN model to make predictions on the test data\n",
    "X_test = test_df[['Class', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "y_test = test_df['Class']\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the KNN model on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Compute the classification report for the KNN model on the test data\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b64ea-09c5-4487-9399-f0ca160f99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model correctly classified 75% of the instances in the test set.\n",
    "# The report indicates that the model performs well in predicting class 1, \n",
    "# with a precision of 0.82 and a recall of 0.90, indicating that it correctly predicted a high proportion of \n",
    "# the instances belonging to this class. However, the model performed less well in predicting classes 0 and 3, \n",
    "# with a precision and recall of around 0.5. The model had moderate performance for class 2, with a precision \n",
    "#and recall of around 0.6, and poor performance for class 4, with a precision of 0.5 and a recall of 0.38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13cac3-7802-4ae1-aab0-e5bf2137a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of values for k\n",
    "k_range = range(1, 80)\n",
    "\n",
    "# Create an empty list to store the cross-validation scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation for each value of k\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(np.mean(scores))\n",
    "\n",
    "# Plot the cross-validation scores as a function of k\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_range, cv_scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Select the best value of k\n",
    "best_k = np.argmax(cv_scores) + 1\n",
    "print(\"The best value of k is:\", best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bcc7e-7280-4d19-880d-305c8114a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can set k=20 in our KNN model to get the best possible performance on this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d9bcb-097c-4d9c-95be-177922b6aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###KNN-SMOTE####\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit SMOTE on the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of samples before and after SMOTE\n",
    "print(\"Number of samples before SMOTE:\", len(X_train))\n",
    "print(\"Number of samples after SMOTE:\", len(X_train_smote))\n",
    "\n",
    "# Train a KNN classifier on the oversampled data\n",
    "knn_smote = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict the test set using the KNN classifier trained on the oversampled data\n",
    "y_pred_smote = knn_smote.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the KNN model with SMOTE on the test data\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "print(\"Accuracy with SMOTE:\", accuracy_smote)\n",
    "\n",
    "# Compute the classification report for the KNN model with SMOTE on the test data\n",
    "report_smote = classification_report(y_test, y_pred_smote)\n",
    "\n",
    "# Print the classification report\n",
    "print(report_smote)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633490e-cb6b-4d30-8199-f79ddab01706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE is used to address class imbalance by creating synthetic samples.\n",
    "# However, in this case, after oversampling with SMOTE, the performance of the KNN classifier on the test set \n",
    "# actually got worse compared to the previous results without SMOTE. The accuracy dropped from 0.7534 to 0.621, \n",
    "# and the overall classification report shows lower precision and recall scores for some classes. \n",
    "#This could be due to overfitting on the training data or other factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e710a6-934e-46fc-a8a9-b78842cd303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Class Imbalance using Random Oversample\n",
    "# Initialize the random oversampler with random_state=0\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "# Resample the training data\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the KNN classifier with k=20\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# Fit the KNN model on the resampled training data\n",
    "knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Use the trained KNN model to make predictions on the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the KNN model on the test data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with RandomOverSampler:\", accuracy)\n",
    "\n",
    "# Compute the classification report for the KNN model on the test data\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4eea7d-ac74-4d4f-964f-92a4a9523816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RandomOverSampler technique to address the class imbalance in the training data. \n",
    "# The accuracy of the model after using Random Oversampling is 0.589. The drop in accuracy could be due to the \n",
    "#fact that the synthetic samples generated by Random Oversampling can add noise to the data, leading to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49fc6e-e5fd-43f0-87ba-d04bfd966b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "y = df['Class']\n",
    "\n",
    "# Create KNN object and run classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_prob = knn.predict_proba(X)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(len(set(y))):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y, y_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = ['red', 'green', 'blue', 'orange', 'purple']\n",
    "for i, color in zip(range(len(set(y))), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30f035-3a77-4f6e-ab65-2d93223b5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####LDA#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83c3a4-862c-4a32-a329-abe61b60b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Matrix X und Zielvariable Y auswÃ¤hlen\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "Y = df['Class']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "# LDA-Modell erstellen und anpassen\n",
    "lda = LDA(solver='lsqr')\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf Testdaten machen\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# LeistungsmaÃe berechnen\n",
    "print('default-rate: {0: .4f}'.format(np.sum(y_test)/len(y_test)))\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Konfusionsmatrix ausgeben\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc0cfe-9b9b-4b8f-ba9b-45a6471cacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this specific case, the default rate is 1.29, which means that the most frequent class in the test set is Class 1\n",
    "# The F1-score is 0.79, which indicates that the model has good accuracy. \n",
    "# The classification report shows precision, recall, and F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c4fcd-eda3-4dc7-8e61-835c39677515",
   "metadata": {},
   "outputs": [],
   "source": [
    "###SMOTE###\n",
    "# Feature-Matrix X und Zielvariable Y auswÃ¤hlen\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "Y = df['Class']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "sm = SMOTE(random_state=0)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# LDA-Modell erstellen und anpassen\n",
    "lda = LDA(solver='lsqr')\n",
    "lda.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Vorhersagen auf Testdaten machen\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Konfusionsmatrix ausgeben\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc574581-2955-45cf-8a1f-d58180e8acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we have also tried to address the class imbalancing problem by applying SMOTE. \n",
    "# But this also led to a deterioration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60d1cf-b000-4661-ba02-88e55adcfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "y = df['Class']\n",
    "\n",
    "# Create LDA object and run classifier\n",
    "lda = LDA(solver='lsqr')\n",
    "lda.fit(X, y)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_prob = lda.predict_proba(X)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(len(set(y))):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y, y_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = ['red', 'green', 'blue', 'orange', 'purple']\n",
    "for i, color in zip(range(len(set(y))), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa227c4-7326-4233-8ae4-63049a0bbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####QDA\n",
    "# Feature-Matrix X und Zielvariable Y auswÃ¤hlen\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "Y = df['Class']\n",
    "\n",
    "# Train-Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# QDA-Modell erstellen und anpassen\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf Testdaten machen\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "# Konfusionsmatrix ausgeben\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235414ce-30f5-4e4d-abee-7b5099cdb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model achieves an accuracy of 0.82, and the precision and recall vary across the classes, \n",
    "# with the highest precision and recall achieved for class 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61ffed-eff6-48f9-807c-bfbfb6ac5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df[['OverallQual', 'GrLivArea', 'GarageArea',\n",
    "       'TotalBsmtSF', '1stFlrSF', 'TotRmsAbvGrd', 'FullBath', 'YearRemodAdd']]\n",
    "y = df['Class']\n",
    "\n",
    "# Create QDA object and run classifier\n",
    "qda = QDA()\n",
    "qda.fit(X, y)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_prob = qda.predict_proba(X)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(len(set(y))):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y, y_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = ['red', 'green', 'blue', 'orange', 'purple']\n",
    "for i, color in zip(range(len(set(y))), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd1e0c-770f-4957-bab5-efea898a268e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
