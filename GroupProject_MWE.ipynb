{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0600489",
   "metadata": {},
   "source": [
    "# Group Project: Minimal Working Expamle\n",
    "\n",
    "Below script is a minimum working example using the group project data to derive a ML-model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b90fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"GroupProjectDataSet.csv\", sep=',')\n",
    "print('Shape of data frame:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess missing values\n",
    "cols = df.columns[df.isna().any()]\n",
    "df_nan = df[cols].copy()\n",
    "df_nan['Class'] = df['Class']\n",
    "print('Percentage of missing values per column:')\n",
    "df_nan.isna().sum() / df_nan.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5025911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missing values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_nan.isna().transpose(),\n",
    "            cmap=\"Blues\",\n",
    "            cbar_kws={'label': 'Missing Values'});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7382179",
   "metadata": {},
   "source": [
    "Assess Class imbalance. You make your own assessment on potential effects of class-imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b533328",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Class'], bins=[0, 1, 2, 3, 4, 5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c8552",
   "metadata": {},
   "source": [
    "Note: I will now drop all columns where NaN-values make up more than 40%. However, this is not a wise step. Read the data description to better understand why. But to not disclose too much of an optimal solution, this is done on purpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c04896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(thresh=df.shape[0]*0.4, how='all', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asign columns to feature matrix X and response vector y\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6795556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute warnings (related to LogReg 'max_iter' param)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    ")\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, selector(dtype_include=np.number)),\n",
    "        (\"cat\", cat_transformer, selector(dtype_include=object)),\n",
    "    ]\n",
    ")\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe369a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"preprocessor__cat__selector__percentile\": [10, 30, 50, 70],\n",
    "    \"classifier__C\": [0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "search_cv = RandomizedSearchCV(clf, param_grid, n_iter=10, random_state=0)\n",
    "search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(search_cv.best_score_))\n",
    "print('Test score:       {:.2f}'.format(search_cv.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(search_cv.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46590209",
   "metadata": {},
   "source": [
    "Now let's see similarly for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1533c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"preprocessor__cat__selector__percentile\": [10, 30, 50, 70],\n",
    "    \"classifier__max_depth\": [1, 3, 5, 10],\n",
    "}\n",
    "\n",
    "search_cv = RandomizedSearchCV(clf, param_grid, n_iter=10, random_state=0)\n",
    "\n",
    "search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(search_cv.best_score_))\n",
    "print('Test score:       {:.2f}'.format(search_cv.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(search_cv.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_selector = selector(dtype_include=object)\n",
    "num_selector = selector(dtype_include=np.number)\n",
    "\n",
    "cat_tree_processor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1,\n",
    "    encoded_missing_value=-2,\n",
    ")\n",
    "num_tree_processor = SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    "\n",
    "tree_preprocessor = make_column_transformer(\n",
    "    (num_tree_processor, num_selector), (cat_tree_processor, cat_selector)\n",
    ")\n",
    "\n",
    "#####\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", tree_preprocessor), (\"classifier\", RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57999e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__max_depth\": [5, 10, 25],\n",
    "}\n",
    "\n",
    "search_cv = RandomizedSearchCV(clf, param_grid, n_iter=10, random_state=0)\n",
    "\n",
    "search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print results\n",
    "print('Best CV accuracy: {:.2f}'.format(search_cv.best_score_))\n",
    "print('Test score:       {:.2f}'.format(search_cv.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(search_cv.best_params_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
